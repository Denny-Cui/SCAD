{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "import os\n",
    "from time import ctime, time, sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn, optim\n",
    "from torch import functional as F\n",
    "from torch.utils import data as Data\n",
    "\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_path = './denny/'\n",
    "cudnn.benchmark = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('note.csv', 'w') as f:  # f = open('note.csv', 'a')\n",
    "    f.write('dataset,hr,ndcg,mrr' + '\\n')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Self_attention(nn.Module):\n",
    "    def __init__(self, dim_q, dim_k, dim_v):\n",
    "        super(Self_attention, self).__init__()\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "\n",
    "        self.linear_q = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_k = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_v = nn.Linear(dim_q, dim_v, bias=False)\n",
    "        self._norm_fact = 1 / np.sqrt(dim_k)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.linear_q(x)  # batch, n, dim_k\n",
    "        k = self.linear_k(x)  # batch, n, dim_k\n",
    "        v = self.linear_v(x)  # batch, n, dim_v\n",
    "        dist = torch.matmul(q, k.transpose(-1, -2)) * self._norm_fact  # batch, n, n\n",
    "        dist = torch.softmax(dist, dim=-1)  # batch, n, n\n",
    "        att = torch.matmul(self.dropout(dist), v)\n",
    "        return att\n",
    "    \n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Add_norm(nn.Module):\n",
    "    \"\"\"Layer normalize after residual connection\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(Add_norm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.layer_norm(self.dropout(Y) + X)\n",
    "    \n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file_to_four(path1, path2):\n",
    "    usrs = open(path1, 'r').readlines()\n",
    "    neighs = open(path2, 'r').readlines()\n",
    "    usr_item = []\n",
    "    neigh_dict = {}\n",
    "    itemids = []\n",
    "\n",
    "    for usr in usrs:\n",
    "        u = usr.split('\\n')[0].split(',')[1:]\n",
    "        usr_item.append(u)\n",
    "        for idx in u:\n",
    "            if idx not in itemids:\n",
    "                itemids.append(idx)\n",
    "\n",
    "    for neigh in neighs:\n",
    "        nei = neigh.split('\\n')[0].split(',')\n",
    "        if nei[0] not in neigh_dict:\n",
    "            neigh_dict[nei[0]] = []\n",
    "        neigh_dict[nei[0]].append(nei[2:])\n",
    "        for idx in nei[2:]:\n",
    "            if idx not in itemids:\n",
    "                itemids.append(idx)\n",
    "\n",
    "    neigh_item = []\n",
    "    for neigh in neigh_dict:\n",
    "        neigh_item.append(neigh_dict[neigh])\n",
    "\n",
    "    print(len(itemids))\n",
    "    return usr_item, itemids, neigh_item\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_itemid(usr_item, itemids, neigh_item):\n",
    "    item_dict = {}  # {itemid1:item1_idx, itemid2:item2_idx, ...} (to handle those discontinuous itemids)\n",
    "    for idx, val in enumerate(itemids):\n",
    "        item_dict[val] = idx\n",
    "    for usr in usr_item:\n",
    "        for idx, val in enumerate(usr):\n",
    "            usr[idx] = item_dict[val]\n",
    "    for neighs in neigh_item:\n",
    "        for neigh in neighs:\n",
    "            for idx, val in enumerate(neigh):\n",
    "                neigh[idx] = item_dict[val]\n",
    "\n",
    "    item_num = len(itemids)\n",
    "    return usr_item, neigh_item, item_num\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_test_dataset(usr_item, neigh_item, item_num):\n",
    "    train_data = []\n",
    "    train_target_data = []\n",
    "    train_neigh_data = []\n",
    "\n",
    "    valid_data = []\n",
    "    valid_target_data = []\n",
    "    valid_neigh_data = []\n",
    "\n",
    "    test_data = []\n",
    "    test_target_data = []\n",
    "    test_neigh_data = []\n",
    "\n",
    "    length = len(usr_item)\n",
    "    pos1 = length * 0.8\n",
    "    pos2 = length * 0.9  # train, valid test\n",
    "    for neighs in neigh_item:\n",
    "        for idx, neigh in enumerate(neighs):\n",
    "            neighs[idx] = neigh[:-1]\n",
    "\n",
    "    for idx, (usr, neighs) in enumerate(zip(usr_item, neigh_item)):\n",
    "        if idx < pos1:\n",
    "            train_data.append(usr[:-1])\n",
    "            train_target_data.append(usr[-1])\n",
    "            train_neigh_data.append(neighs)\n",
    "        elif idx < pos2:\n",
    "            valid_data.append(usr[:-1])\n",
    "            valid_target_data.append(usr[-1])\n",
    "            valid_neigh_data.append(neighs)\n",
    "        else:\n",
    "            test_data.append(usr[:-1])\n",
    "            test_target_data.append(usr[-1])\n",
    "            test_neigh_data.append(neighs)\n",
    "\n",
    "    return train_data, train_target_data, train_neigh_data, valid_data, valid_target_data, valid_neigh_data, test_data, test_target_data, test_neigh_data, item_num\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, layer_num, item_num, seq_len, k=4):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.item_num = item_num\n",
    "        self.embedding = nn.Embedding(self.item_num, input_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.gru = nn.GRU(input_size=self.input_dim, hidden_size=self.hid_dim, num_layers=self.layer_num, batch_first=True)\n",
    "        self.k = k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.self_att1 = Self_attention(self.input_dim, self.input_dim, self.input_dim)\n",
    "        self.attention = d2l.DotProductAttention(0.5)\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.q1 = nn.Linear(self.seq_len, self.seq_len, bias=False)\n",
    "        self.k1 = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.v1 = nn.Linear(input_dim, input_dim, bias=False)\n",
    "\n",
    "        self.add_norm1 = Add_norm(input_dim, 0.5)\n",
    "        self.add_norm2 = Add_norm(self.seq_len, 0.5)\n",
    "\n",
    "        self.yita = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "        attention1_module = []\n",
    "        attention1_module.append(nn.Linear(self.hid_dim, self.hid_dim // 2))\n",
    "        attention1_module.append(nn.Dropout(0.5))\n",
    "        self.attention1 = nn.Sequential(*attention1_module)\n",
    "\n",
    "        attention2_module = []\n",
    "        attention2_module.append(nn.Linear(self.hid_dim // 2, 1))\n",
    "        attention2_module.append(nn.Dropout(0.5))\n",
    "        self.attention2 = nn.Sequential(*attention2_module)\n",
    "\n",
    "        self.mu = nn.Sequential(nn.Linear(self.input_dim, self.input_dim * self.k), nn.ReLU(),\n",
    "                                nn.Linear(self.input_dim * self.k, self.input_dim))\n",
    "        \n",
    "    def tar_att1(self, x, y):\n",
    "        Q = self.q1(x)\n",
    "        K = self.k1(y)\n",
    "        V = self.v1(y)\n",
    "        A = torch.matmul(Q, K) / np.sqrt(self.input_dim)\n",
    "        A = torch.softmax(A, dim=-1)\n",
    "        O = torch.matmul(A, V.transpose(-1, -2))\n",
    "        return O\n",
    "    \n",
    "    def squashing(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / (squared_norm.sqrt() + 1e-8)\n",
    "    \n",
    "    def single_dynamic_routing(self, neigh):\n",
    "        b = torch.zeros(self.seq_len).to(device)  # [6]\n",
    "        neigh = neigh.to(device)  # [6, 128]\n",
    "        # a_pis = []\n",
    "        for i in range(3):\n",
    "            att_w = self.tar_att1(b, neigh)  # [6]\n",
    "            c = torch.softmax(b, dim=-1) * self.add_norm2(b, att_w)  # [6]\n",
    "            c = torch.softmax(c, dim=-1)  # [6]\n",
    "            s = c @ neigh  # [1,6] @ [6, 128] = [128]\n",
    "            a = self.squashing(s)  # [128]\n",
    "            b = b + a @ neigh.transpose(-1, -2)  # [6]\n",
    "            # a_pis.append(a)\n",
    "            # if i == 0:\n",
    "            #     a_pi = a\n",
    "        # return a\n",
    "        return a  # , a_pi  # [128], [3, 128]\n",
    "    \n",
    "    def single_dynamic_routing_after(self, usr, a_original, a_pi):\n",
    "        # b_1, b_2, b_3 = torch.zeros(1).to(device), torch.zeros(self.seq_len).to(device), torch.zeros(1).to(device)  # [1], [1]\n",
    "        # b_1, b_2, b_3 = torch.zeros(1).to(device), torch.zeros(self.seq_len - 1).to(device), torch.zeros(1).to(device)\n",
    "        b_1, b_2, b_3 = torch.zeros(1).to(device), torch.zeros(1).to(device), torch.zeros(1).to(device)\n",
    "        a_original, usr, a_pi = a_original.to(device), usr.to(device), a_pi.to(device)   # [128]\n",
    "        for _ in range(3):\n",
    "            # a_original = a_original.to(device)  # [128]\n",
    "            # a_former = a\n",
    "            c_1, c_2, c_3 = torch.softmax(b_1, dim=-1), torch.softmax(b_2, dim=-1), torch.softmax(b_3, dim=-1)  # [1], [1]\n",
    "            s = c_1 @ a_original.unsqueeze(0) + c_2 @ usr.unsqueeze(0) + c_3 @ a_pi.unsqueeze(0)  # [128]\n",
    "            a = self.squashing(s)  # [128]\n",
    "            b_1, b_2, b_3 = b_1 + a @ a_original.unsqueeze(1), b_2 + a @ usr.unsqueeze(1), b_3 + a @ a_pi.unsqueeze(1)  # [1], [1]\n",
    "        # a = nn.Linear(256, 128)(torch.concat((a, a_orginal), dim=0)).to(device)\n",
    "        # print('a:', a.shape)\n",
    "        return a  # [128]\n",
    "\n",
    "    \n",
    "    def multi_dynamic_routing(self, neigh):\n",
    "        b = torch.randn(self.k, self.seq_len).to(device)  # [4, 6]\n",
    "        neigh = neigh.to(device)  # [6, 128]\n",
    "        for i in range(3):\n",
    "            att_w = self.tar_att1(b, neigh)  # [4, 6]\n",
    "            c = torch.softmax(b, dim=-1) * self.add_norm2(b, att_w)  # [4, 6]\n",
    "            c = torch.softmax(c, dim=-1)  # [4, 6]\n",
    "            s = c @ neigh  # [4, 128]\n",
    "            a = self.squashing(s)  # [4, 128]\n",
    "            if i < 2:\n",
    "                b = b + a @ neigh.transpose(-1, -2)  # [4, 6]\n",
    "        return a  # [4, 128]\n",
    "    \n",
    "    def usr_add_attention(self, outs):\n",
    "        ret = 0\n",
    "        usr_hn = outs[:, -1, :]\n",
    "        usr_hn = usr_hn.to(device)  # [, ]\n",
    "        usr_hn = self.attention1(usr_hn)  # [, ]\n",
    "        for i in range(outs.shape[1]):\n",
    "            usr_hi = outs[:, i, :]\n",
    "            usr_hi = usr_hi.to(device)\n",
    "            usr_hi = self.attention1(usr_hi)\n",
    "            sig_hi_hn = self.sigmoid(usr_hn +usr_hi)\n",
    "            att = self.attention2(sig_hi_hn).cpu()\n",
    "            ret += att * outs[:, i, :].cpu()\n",
    "        return ret\n",
    "\n",
    "    def forward(self, train_data, train_neigh_data, target=None):\n",
    "        # embedding for train_data\n",
    "        train_data = train_data.to(device)\n",
    "        train_data  = self.embedding(train_data)\n",
    "        # embedding for neighbor\n",
    "        train_neigh_data = train_neigh_data.to(device)\n",
    "        train_neigh_data = self.embedding(train_neigh_data)  # [, , , ]\n",
    "\n",
    "        batch_size = train_data.shape[0]\n",
    "        usr_hidden = torch.zeros(self.layer_num, batch_size, self.hid_dim).contiguous().to(device)\n",
    "        outs, usr_hidden = self.gru(train_data, usr_hidden)  # [, ,], [, ,]\n",
    "\n",
    "        outs = self.usr_add_attention(outs)\n",
    "        gru_out = torch.zeros(outs.shape[0], outs.shape[1]).to(device)\n",
    "        gru_out2 = torch.zeros(outs.shape[0], self.k, outs.shape[1]).to(device)\n",
    "        cnt = 0\n",
    "\n",
    "        for usr, neigh in zip(outs, train_neigh_data):\n",
    "            hidden = torch.zeros(self.layer_num, neigh.shape[0], self.hid_dim).contiguous().to(device)\n",
    "            nei_out, hidden = self.gru(neigh, hidden)\n",
    "            usr = usr.to(device)\n",
    "            nei_out = torch.concat((nei_out, usr.repeat(self.seq_len - 1, 1, 1)), dim=1)\n",
    "            nei_out = self.usr_add_attention(nei_out)  # [, ]\n",
    "            nei = torch.zeros(nei_out.shape[0] + 1, nei_out.shape[1])\n",
    "            nei[0] = usr\n",
    "            for idx, i in enumerate(nei_out):\n",
    "                nei[idx + 1] = i\n",
    "            nei = nei.to(device)\n",
    "            after = self.self_att1(nei)\n",
    "            nei = self.add_norm1(nei, after)  # [6, 128]\n",
    "            # a, a_pi = self.single_dynamic_routing(nei)\n",
    "            # a_pis = [a_pi.to(device) for a_pi in a_pis]\n",
    "            usr = torch.Tensor(usr).to(device)\n",
    "            # a_after = self.single_dynamic_routing_after(usr, a, a_pi)\n",
    "            # linear_layer = nn.Linear(256, 128).to(device)\n",
    "            # gru_out[cnt] = linear_layer(torch.concat((a_after, a), dim=0))\n",
    "            # gru_out[cnt] = gru_out[cnt].to(device)\n",
    "            nei_pi = nei[1:]\n",
    "            # gru_out[cnt] = self.single_dynamic_routing_after(usr, a, a_pi)\n",
    "            gru_out[cnt] = self.single_dynamic_routing(nei)\n",
    "            gru_out2[cnt] = self.multi_dynamic_routing(nei)\n",
    "            cnt += 1\n",
    "        \n",
    "        item_embedding = [i for i in range(self.item_num)]\n",
    "        item_embedding = torch.LongTensor(item_embedding).to(device)\n",
    "        item_embedding = self.embedding(item_embedding)\n",
    "\n",
    "        score1 = gru_out @ item_embedding.T\n",
    "        score2 = gru_out2 @ item_embedding.T\n",
    "        score2 = torch.max(score2, 1).values\n",
    "        score = self.yita * score1 + (1 - self.yita) * score2\n",
    "        return score.cpu()\n",
    "    \n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:15 2024'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Metrics(model, test_loader, test_usr_neigh_data, top_k, batch_size):\n",
    "    hr = 0\n",
    "    ndcg = 0\n",
    "    mrr = 0\n",
    "    usr_num = 0\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    for x, y, neigh in test_loader:\n",
    "        x, neigh = x.to(device), neigh.to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model(x, neigh)\n",
    "        usr_num += scores.shape[0]\n",
    "        scores = scores.to(device)\n",
    "        scores, top_k_item_pos = torch.topk(scores, top_k)\n",
    "        scores = scores.cpu()\n",
    "        top_k_item_pos = top_k_item_pos.cpu()\n",
    "\n",
    "        for next_item_pos, top_k_item_pos_per in zip(y, top_k_item_pos):\n",
    "            if next_item_pos in top_k_item_pos_per:\n",
    "                hr += 1\n",
    "                top_k_item_pos_per = top_k_item_pos_per.detach().numpy().tolist()\n",
    "                idx = top_k_item_pos_per.index(next_item_pos)\n",
    "                mrr += 1 / (idx + 1)\n",
    "                ndcg += np.reciprocal(np.log2(idx + 2))\n",
    "    hr = hr / usr_num\n",
    "    ndcg = ndcg / usr_num\n",
    "    mrr = mrr / usr_num\n",
    "    return hr, ndcg, mrr\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2, step_size=0.1, max_margin=0.9):\n",
    "        super(SpreadLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.step_size = step_size\n",
    "        self.max_margin = max_margin\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        batch_size = output.size(0)\n",
    "        num_classes = output.size(1)\n",
    "\n",
    "        target_one_hot = torch.eye(num_classes).to(device)[target]\n",
    "\n",
    "        a_t = (output * target_one_hot).sum(dim=1)\n",
    "        a_i = output * (1 - target_one_hot)\n",
    "\n",
    "        loss = torch.clamp(self.margin - (a_t.view(batch_size, 1) - a_i), min=0) ** 2\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "        return loss\n",
    "    \n",
    "    def update_margin(self):\n",
    "        self.margin = min(self.max_margin, self.margin + self.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:16 2024'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(train_data, train_target_data, train_neigh_data,\n",
    "          valid_data, valid_target_data, valid_neigh_data,\n",
    "          gru_input, gru_output, gru_layer_num,\n",
    "          batch_size, item_num, seq_len, dataset_name, top_k, model_type, model, k):\n",
    "      train_dataset = Data.TensorDataset(train_data, train_target_data, train_neigh_data)\n",
    "      train_loader = Data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "      valid_dataset = Data.TensorDataset(valid_data, valid_target_data, valid_neigh_data)\n",
    "      valid_loader = Data.DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "      print(f'dataset: {dataset_name}, model_type: {model_type}, topN: {top_k}, k: {k}')\n",
    "      loss_fun = nn.CrossEntropyLoss()\n",
    "      # loss_fun = SpreadLoss()\n",
    "      optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "      loss_fun = loss_fun.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "\n",
    "      print('training ... ', ctime())\n",
    "\n",
    "      best_ndcg = 0\n",
    "      best_hr = 0\n",
    "      best_mrr = 0\n",
    "      epoch = 100\n",
    "\n",
    "      # animator = d2l.Animator(xlabel='epoch', xlim=[1, 30], legend=['HR', 'NDCG', 'MRR', 'loss'])\n",
    "      # timer = d2l.Timer()\n",
    "\n",
    "      model_name = dataset_name + '_' + str(model_type) + '_' + str(top_k) + '_k' + str(k)\n",
    "      threshold = 2\n",
    "      cnt = 0\n",
    "      for i in range(epoch):\n",
    "            model.train()\n",
    "            loss_total = 0\n",
    "            train_pbar = tqdm(train_loader, position=0, ncols=100)\n",
    "            for data, target, neigh in train_pbar:\n",
    "                  # timer.start()\n",
    "                  data, target, neigh = data.to(device), target.to(device), neigh.to(device)\n",
    "                  model = model.to(device)\n",
    "                  score = model(data, neigh, target)\n",
    "                  score = score.to(device)\n",
    "                  loss = loss_fun(score, target)\n",
    "                  optimizer.zero_grad()\n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                  loss_total += loss.item()\n",
    "                  # timer.stop()\n",
    "                  train_pbar.set_description(f'Epoch [{i + 1}/{epoch}]')\n",
    "                  train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "            print(i + 1, loss_total / len(train_loader), ctime())\n",
    "            # loss_fun.update_margin()\n",
    "\n",
    "            model.eval()\n",
    "            hr, ndcg, mrr = Metrics(model, valid_loader, valid_neigh_data, top_k, batch_size)\n",
    "            # animator.add(i + 1, (hr, ndcg, mrr, loss_total / len(train_loader)))\n",
    "            # plt.pause(0.1)\n",
    "            # plt.show()\n",
    "            # print(f'Epoch [{i + 1}/{epoch}]', ctime())\n",
    "            print('valid_HR:', hr)\n",
    "            print('valid_NDCG:', ndcg)\n",
    "            print('valid_MRR:', mrr)\n",
    "\n",
    "            flag = False\n",
    "            if hr > best_hr:\n",
    "                  best_hr = hr\n",
    "                  cnt = 0\n",
    "                  flag = True\n",
    "            if ndcg > best_ndcg:\n",
    "                  print(dataset_name + '_' + str(model_type) + '_' + str(top_k) + '_' + str(k))\n",
    "                  torch.save(model.state_dict(), model_name + '.pth')\n",
    "                  best_ndcg = ndcg\n",
    "                  cnt = 0\n",
    "                  flag = True\n",
    "            if mrr > best_mrr:\n",
    "                  best_mrr = mrr\n",
    "                  cnt = 0\n",
    "                  flag = True\n",
    "            print('best_HR:', best_hr)\n",
    "            print('best_NDCG:', best_ndcg)\n",
    "            print('best_MRR:', best_mrr)\n",
    "            f = open('./process.txt', 'a')\n",
    "            f.write(model_name + '  ')\n",
    "            s1 = 'valid: ' + 'HR: ' + str(hr) + ' NDCG: ' + str(ndcg) + ' MRR: ' + str(mrr)\n",
    "            f.write(s1 + '\\n')\n",
    "            f.close()\n",
    "            if not flag:\n",
    "                  cnt += 1\n",
    "            if cnt >= threshold:\n",
    "                  break\n",
    "      return model_name\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Aug  5 17:59:16 2024'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_data, test_target_data, test_neigh_data,\n",
    "        gru_input_feature, gru_output_feature, gru_layer_num,\n",
    "        batch_size, item_num, seq_len, dataset_name, top_k, model_type, model_name, k):\n",
    "    print(f'{dataset_name} testing ...', ctime())\n",
    "    test_dataset = Data.TensorDataset(test_data, test_target_data, test_neigh_data)\n",
    "    test_loader = Data.DataLoader(test_dataset, batch_size, shuffle=False, num_workers=4)\n",
    "    print(f'dataset: {dataset_name} model_type: {model_type} topN: {top_k}, k: {k}')\n",
    "\n",
    "    model = GRUModel(gru_input_feature, gru_output_feature, gru_layer_num, item_num, seq_len, k).to(device)\n",
    "    print(model_name + '.pth')\n",
    "    model.load_state_dict(torch.load(model_name + '.pth'))\n",
    "    model.eval()\n",
    "    test_hr, test_ndcg, test_mrr = Metrics(model, test_loader, test_neigh_data, top_k, batch_size)\n",
    "    print('test_HR:', test_hr)\n",
    "    print('test_NDCG:', test_ndcg)\n",
    "    print('test_MRR:', test_mrr)\n",
    "    f = open('note.csv', 'a')\n",
    "    f.write(model_name + ',')\n",
    "    # s2 = 'test: ' + 'HR: ' + str(test_hr) + ' NDCG: ' + str(test_ndcg) + ' MRR: ' + str(test_mrr)\n",
    "    s2 = str(test_hr) + ',' + str(test_ndcg) + ',' + str(test_mrr)\n",
    "    f.write(s2 + '\\n')\n",
    "    f.close()\n",
    "\n",
    "ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: Mon Aug  5 17:59:16 2024\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/lfm/user_item_8.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m path1 \u001b[38;5;241m=\u001b[39m basic_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/user_item_8.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m path2 \u001b[38;5;241m=\u001b[39m basic_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/user_item_neigh.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m usr_item, itemids, neigh_item \u001b[38;5;241m=\u001b[39m \u001b[43mread_file_to_four\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m usr_item, neigh_item, item_num \u001b[38;5;241m=\u001b[39m get_itemid(usr_item, itemids, neigh_item)\n\u001b[0;32m     16\u001b[0m train_data, train_target_data, train_neigh_data, valid_data, valid_target_data, valid_neigh_data, test_data, test_target_data, test_neigh_data, item_num \u001b[38;5;241m=\u001b[39m get_train_test_dataset(usr_item, neigh_item, item_num)\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mread_file_to_four\u001b[1;34m(path1, path2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file_to_four\u001b[39m(path1, path2):\n\u001b[1;32m----> 2\u001b[0m     usrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      3\u001b[0m     neighs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(path2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      4\u001b[0m     usr_item \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Users\\Hitori\\anaconda3\\envs\\mainTorch\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/lfm/user_item_8.csv'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4719)\n",
    "print(f'start: {ctime()}')\n",
    "batch_size = 64\n",
    "gru_layer_num = 2\n",
    "gru_input_feature = 128\n",
    "gru_output_feature = 128\n",
    "seq_len = 6\n",
    "datasets = ['lfm', 'yoochoose']\n",
    "topn, model_type, k = 5, 'SCAD', 4\n",
    "\n",
    "for dataset in datasets:\n",
    "    path1 = basic_path + 'dataset/' + dataset + '/user_item_8.csv'\n",
    "    path2 = basic_path + 'dataset/' + dataset + '/user_item_neigh.csv'\n",
    "    usr_item, itemids, neigh_item = read_file_to_four(path1, path2)\n",
    "    usr_item, neigh_item, item_num = get_itemid(usr_item, itemids, neigh_item)\n",
    "    train_data, train_target_data, train_neigh_data, valid_data, valid_target_data, valid_neigh_data, test_data, test_target_data, test_neigh_data, item_num = get_train_test_dataset(usr_item, neigh_item, item_num)\n",
    "\n",
    "    train_data = torch.LongTensor(train_data)  # [9190, 7]\n",
    "    train_target_data = torch.LongTensor(train_target_data)  # [9190]\n",
    "    train_neigh_data = torch.LongTensor(train_neigh_data)  # [9190, 5, 7]\n",
    "    print('train:', train_data.shape, train_target_data.shape, train_neigh_data.shape)\n",
    "\n",
    "    valid_data = torch.LongTensor(valid_data)  # [1149, 7]\n",
    "    valid_target_data = torch.LongTensor(valid_target_data)  # [1149]\n",
    "    valid_neigh_data = torch.LongTensor(valid_neigh_data)  # [1149, 5, 7]\n",
    "    print('valid:', valid_data.shape, valid_target_data.shape, valid_neigh_data.shape)\n",
    "\n",
    "    test_data = torch.LongTensor(test_data)  # [1148, 7]\n",
    "    test_target_data = torch.LongTensor(test_target_data)  # [1148]\n",
    "    test_neigh_data = torch.LongTensor(test_neigh_data)  # [1148, 5, 7]\n",
    "    print('test:', test_data.shape, test_target_data.shape, test_neigh_data.shape)\n",
    "\n",
    "    model = GRUModel(gru_input_feature, gru_output_feature,gru_layer_num, item_num, seq_len, k)\n",
    "\n",
    "    model_name = train(train_data, train_target_data, train_neigh_data,\n",
    "                    valid_data, valid_target_data, valid_neigh_data,\n",
    "                    gru_input_feature, gru_output_feature, gru_layer_num,\n",
    "                    batch_size, item_num, seq_len, dataset, topn, model_type, model, k)\n",
    "    print(f'{dataset} train finished')\n",
    "\n",
    "    test(test_data, test_target_data, test_neigh_data,\n",
    "        gru_input_feature, gru_output_feature, gru_layer_num,\n",
    "        batch_size, item_num, seq_len, dataset, topn, model_type, model_name, k)\n",
    "    print('test finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn, model_type, k = 5, 'SCAD', 4\n",
    "\n",
    "# model = GRUModel(gru_input_feature, gru_output_feature,gru_layer_num, item_num, seq_len, k)\n",
    "\n",
    "# model_name = train(train_data, train_target_data, train_neigh_data,\n",
    "#                    valid_data, valid_target_data, valid_neigh_data,\n",
    "#                    gru_input_feature, gru_output_feature, gru_layer_num,\n",
    "#                    batch_size, item_num, seq_len, dataset, topn, model_type, model, k)\n",
    "# print('train finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(test_data, test_target_data, test_neigh_data,\n",
    "#      gru_input_feature, gru_output_feature, gru_layer_num,\n",
    "#      batch_size, item_num, seq_len, dataset, topn, model_type, model_name, k)\n",
    "# print('test finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
